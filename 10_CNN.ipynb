{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 샘플1 : 3 * 3 * 1 * 1 이미지 준비, 2 * 2 * 1 필터 준비 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bae192ee08>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.array([[[[1], [2], [3]], \n",
    "                   [[4], [5], [6]],\n",
    "                   [[7],[8], [9]]]], dtype=np.float32)\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(3, 3), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n",
      "[[12. 16.]\n",
      " [24. 28.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# padding없이 convolution layer 추출\n",
    "\n",
    "filter = tf.constant([[[[1.]], [[1.]]], \n",
    "                      [[[1.]], [[1.]]]])\n",
    "filter.shape\n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1, 1, 1, 1], padding=\"VALID\")\n",
    "\n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "print(conv2d_img.shape)\n",
    "\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i , one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(2, 2))\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.imshow(one_img.reshape(2,2), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# padding을 이용한 convolution layer 추출\n",
    "\n",
    "filter = tf.constant([[[[1.]], [[1.]]], \n",
    "                      [[[1.]], [[1.]]]])\n",
    "filter.shape\n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "print(conv2d_img.shape)\n",
    "\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i , one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3, 3))\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.imshow(one_img.reshape(3, 3), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 3)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n",
      "[[120. 160.  90.]\n",
      " [240. 280. 150.]\n",
      " [150. 170.  90.]]\n",
      "[[-12. -16.  -9.]\n",
      " [-24. -28. -15.]\n",
      " [-15. -17.  -9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3개의 필터 사용(2*2*1*3)\n",
    "\n",
    "filter = tf.constant([[[[1., 10, -1]], [[1., 10, -1]]], \n",
    "                      [[[1., 10, -1]], [[1., 10, -1]]]])\n",
    "filter.shape\n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "print(conv2d_img.shape)\n",
    "\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i , one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3, 3))\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(one_img.reshape(3, 3), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 1)\n",
      "[[[[4]]]]\n"
     ]
    }
   ],
   "source": [
    "# MaxPooling(2*2), padding 없이\n",
    "\n",
    "image2 = tf.constant([[[[4], [3]], \n",
    "                       [[2], [1]]]])\n",
    "\n",
    "pool = tf.nn.max_pool(image2, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], \n",
    "                     padding=\"VALID\")\n",
    "\n",
    "sess = tf.Session()\n",
    "p = sess.run(pool)\n",
    "print(p.shape)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n",
      "[[[[4]\n",
      "   [3]]\n",
      "\n",
      "  [[2]\n",
      "   [1]]]]\n"
     ]
    }
   ],
   "source": [
    "# MaxPooling(2*2), padding 사용\n",
    "\n",
    "image2 = tf.constant([[[[4], [3]], \n",
    "                       [[2], [1]]]])\n",
    "\n",
    "pool = tf.nn.max_pool(image2, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], \n",
    "                     padding=\"SAME\")\n",
    "\n",
    "sess = tf.Session()\n",
    "p = sess.run(pool)\n",
    "print(p.shape)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST를 이용한 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-91728e189d13>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bae4c802c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "img = mnist.train.images[0]\n",
    "print(img.shape)\n",
    "\n",
    "plt.imshow(img.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# 입력값 준비\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 Convolution Layer 준비\n",
    "# 필터 : 크기는 3*3, 갯수는 32, 색상수는 1\n",
    "\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "print(L1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "print(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "print(L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 두 번째 Convolution Layer 준비\n",
    "# 필터 : 크기는 3*3, 갯수 64, 색상수는 1\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "print(L2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "print(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "print(L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.723661991\n",
      "Epoch: 0002 cost= 0.178065440\n",
      "Epoch: 0003 cost= 0.122264901\n",
      "Epoch: 0004 cost= 0.094813403\n",
      "Epoch: 0005 cost= 0.079643511\n",
      "Epoch: 0006 cost= 0.070893042\n",
      "Epoch: 0007 cost= 0.062309487\n",
      "Epoch: 0008 cost= 0.055871206\n",
      "Epoch: 0009 cost= 0.049974251\n",
      "Epoch: 0010 cost= 0.046434582\n",
      "Epoch: 0011 cost= 0.043122147\n",
      "Epoch: 0012 cost= 0.040051523\n",
      "Epoch: 0013 cost= 0.036788579\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-03e914a708aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "################## Fully Connected Layer (Dense Layer) #################\n",
    "\n",
    "### hyper parameter 준비\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 500\n",
    "\n",
    "### tensor graph 작성\n",
    "L2 = tf.reshape(L2, [-1, 7*7*64])\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([7*7*64, 10]))\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 비용 계산\n",
    "logit = tf.matmul(L2, W3) + b\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                labels=y))\n",
    "\n",
    "# 최저 비용 구하기\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "### tensor graph 실행\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], feed_dict={X:batch_xs, y:batch_ys})\n",
    "        avg_cost += c/total_batch\n",
    "        \n",
    "    print(\"Epoch:\", \"%04d\"%(epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 :  0.9833\n"
     ]
    }
   ],
   "source": [
    "# 정확도\n",
    "is_correct = tf.equal(tf.argmax(logit, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print(\"정확도 : \", sess.run(accuracy, feed_dict={X:mnist.test.images,\n",
    "                                             y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep FC\n",
    "\n",
    "+ 레이어 총 3개 사용, 입출력 갯수 128개 사용\n",
    "+ xavier 초기화\n",
    "+ dropout 사용\n",
    "+ training_epoch : 15\n",
    "+ batch_size : 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.466600628\n",
      "Epoch: 0002 cost= 0.148043171\n",
      "Epoch: 0003 cost= 0.108409341\n",
      "Epoch: 0004 cost= 0.088602800\n",
      "Epoch: 0005 cost= 0.071219196\n",
      "Epoch: 0006 cost= 0.063818301\n",
      "Epoch: 0007 cost= 0.055499472\n",
      "Epoch: 0008 cost= 0.048639586\n",
      "Epoch: 0009 cost= 0.043806544\n",
      "Epoch: 0010 cost= 0.041516048\n",
      "Epoch: 0011 cost= 0.035260138\n",
      "Epoch: 0012 cost= 0.034086327\n",
      "Epoch: 0013 cost= 0.029076980\n",
      "Epoch: 0014 cost= 0.028816646\n",
      "Epoch: 0015 cost= 0.025584352\n",
      "정확도 :  0.9908\n"
     ]
    }
   ],
   "source": [
    "### hyper parameter 준비\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "prob = tf.placeholder(tf.float32)\n",
    "\n",
    "### 첫번째 레이어\n",
    "L3 = tf.reshape(L2, [-1, 7*7*64])\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[7*7*64, 128], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([128]))\n",
    "logit3 = tf.matmul(L3, W3) + b3\n",
    "L3 = tf.nn.relu(logit3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=prob)\n",
    "\n",
    "### 두번째 레이어\n",
    "W4 = tf.get_variable(\"W4\", shape=[128, 128], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([128]))\n",
    "logit4 = tf.matmul(L3, W4) + b4\n",
    "L4 = tf.nn.relu(logit4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=prob)\n",
    "\n",
    "### 세번째 레이어\n",
    "W5 = tf.get_variable(\"W5\", shape=[128, 10], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logit5 = tf.matmul(L4, W5) + b5\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit5,\n",
    "                                                                labels=y))\n",
    "\n",
    "# 최저 비용 구하기\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "### tensor graph 실행\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], feed_dict={X:batch_xs, y:batch_ys,\n",
    "                                                 prob:0.7})\n",
    "        avg_cost += c/total_batch\n",
    "        \n",
    "    print(\"Epoch:\", \"%04d\"%(epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "   \n",
    "\n",
    " ### 정확도\n",
    "is_correct = tf.equal(tf.argmax(logit5, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print(\"정확도 : \", sess.run(accuracy, feed_dict={X:mnist.test.images,\n",
    "                                             y:mnist.test.labels, prob:1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교통 표지판 인식\n",
    "\n",
    "+ https://benchmark.ini.rub.de/gtsrb_dataset.html\n",
    "    + GTSRB_Final_Test_Images.zip\n",
    "    + GTSRB_Final_Training_Images.zip\n",
    "    \n",
    "    \n",
    "+ 이미지(32 * 32) > Conv Layer1(Pooling) > Conv Layer2(Pooling) > FC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.color import rgb2lab\n",
    "from skimage.transform import resize\n",
    "from collections import namedtuple\n",
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상수 정의\n",
    "N_CLASSES = 43\n",
    "RESIZED_IMAGE = (32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X',\n",
       " '__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_asdict',\n",
       " '_field_defaults',\n",
       " '_fields',\n",
       " '_fields_defaults',\n",
       " '_make',\n",
       " '_replace',\n",
       " 'count',\n",
       " 'index',\n",
       " 'y']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset = namedtuple(\"Dataset\", [\"X\", 'y'])\n",
    "dir(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-1b204789a8d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m ds = read_dataset_ppm(\"C:/Users/user/Documents/jun/AI/GTSRB/Final_Training/Images\", N_CLASSES, \n\u001b[1;32m---> 27\u001b[1;33m                       RESIZED_IMAGE)\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-1b204789a8d9>\u001b[0m in \u001b[0;36mread_dataset_ppm\u001b[1;34m(rootpath, n_labels, resize_to)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"*.ppm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrgb2lab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize_to\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"reflect\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\skimage\\color\\colorconv.py\u001b[0m in \u001b[0;36mrgb2lab\u001b[1;34m(rgb, illuminant, observer)\u001b[0m\n\u001b[0;32m   1090\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwikipedia\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morg\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mwiki\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mStandard_illuminant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m     \"\"\"\n\u001b[1;32m-> 1092\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mxyz2lab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgb2xyz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0milluminant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobserver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\skimage\\color\\colorconv.py\u001b[0m in \u001b[0;36mxyz2lab\u001b[1;34m(xyz, illuminant, observer)\u001b[0m\n\u001b[0;32m    981\u001b[0m     \u001b[1;31m# Nonlinear distortion and linear transformation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.008856\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 983\u001b[1;33m     \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    984\u001b[0m     \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7.787\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m16.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m116.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def to_tf_format(imgs):\n",
    "    return np.stack([img[:, :, np.newaxis] for img in imgs], axis=0).astype(np.float32)\n",
    "\n",
    "# 이미지 크기를 재조정하고 색상은 회색조로 변경, one-hot encoding\n",
    "def read_dataset_ppm(rootpath, n_labels, resize_to):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for c in range(n_labels):\n",
    "        full_path = rootpath + \"/\" + format(c, '05d') + \"/\"\n",
    "        \n",
    "        for img_name in glob.glob(full_path + \"*.ppm\"):\n",
    "            img = plt.imread(img_name).astype(np.float32)\n",
    "            img = rgb2lab(img/255.0)[:, :, 0]\n",
    "            \n",
    "            img = resize(img, resize_to, mode=\"reflect\")\n",
    "            \n",
    "            label = np.zeros((n_labels,), dtype=np.float32 )\n",
    "            label[c] = 1.0\n",
    "            \n",
    "            images.append(img.astype(np.float32))\n",
    "            labels.append(label)\n",
    "\n",
    "    return Dataset(X=to_tf_format(images), y=np.array(labels))\n",
    "#------------------------------------\n",
    "ds = read_dataset_ppm(\"C:/Users/user/Documents/jun/AI/GTSRB/Final_Training/Images\", N_CLASSES, \n",
    "                      RESIZED_IMAGE)\n",
    "\n",
    "print(ds.X.shape)\n",
    "print(ds.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "plt.imshow(ds.X[0,:,:,:].reshape(RESIZED_IMAGE))\n",
    "print(ds.y[0, :])\n",
    "\n",
    "plt.imshow(ds.X[-1,:,:,:].reshape(RESIZED_IMAGE))\n",
    "print(ds.y[-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29406, 32, 32, 1)\n",
      "(9803, 32, 32, 1)\n",
      "(29406, 43)\n",
      "(9803, 43)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 테스트 데이터 분리\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_test, y_train, y_test= train_test_split(range(ds.X.shape[0]), \n",
    "#                                                   ds.y, test_size=0.25, \n",
    "#                                                   random_state=101)\n",
    "\n",
    "#np.array(X_train).shape\n",
    "\n",
    "idx_train, idx_test= train_test_split(range(ds.X.shape[0]), test_size=0.25, \n",
    "                                      random_state=101)\n",
    "\n",
    "X_train = ds.X[idx_train, :, :, :]\n",
    "X_test = ds.X[idx_test, :, :, :]\n",
    "y_train = ds.y[idx_train, :]\n",
    "y_test = ds.y[idx_test, :]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련(학습)과 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 미니배치 준비\n",
    "def minibatcher(X, y, batch_size, shuffle):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    if shuffle:\n",
    "        idx = np.random.permutation(n_samples)\n",
    "    else:\n",
    "        idx = list(range(n_samples))\n",
    "        \n",
    "    for i in range(int(np.ceil(n_samples/batch_size))):\n",
    "        from_idx = i * batch_size\n",
    "        to_idx = (i+1) * batch_size\n",
    "        yield X[idx[from_idx : to_idx], :, :, :], y[idx[from_idx : to_idx], :]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 1) (10000, 43)\n",
      "(10000, 32, 32, 1) (10000, 43)\n",
      "(9406, 32, 32, 1) (9406, 43)\n"
     ]
    }
   ],
   "source": [
    "### 미니배치 함수 테스트\n",
    "for i in minibatcher(X_train, y_train, 10000, True):\n",
    "    print(i[0].shape, i[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_no_activation_layer(in_tensors, n_units):\n",
    "    W = tf.get_variable(\"fc_W\", shape=[in_tensors.get_shape()[1], n_units], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b = tf.get_variable(\"fc_b\", shape=[n_units],\n",
    "                       initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "    return tf.matmul(in_tensors, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_layer(in_tensors, n_units):\n",
    "    return tf.nn.leaky_relu(fc_no_activation_layer(in_tensors, n_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(in_tensors, kernel_size, n_units):\n",
    "    W = tf.get_variable(\"conv_W\", [kernel_size, kernel_size, \n",
    "                                  in_tensors.get_shape()[3], n_units], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b = tf.get_variable(\"conv_b\", shape=[n_units],\n",
    "                       initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "    return tf.nn.leaky_relu(tf.nn.conv2d(in_tensors, W, [1, 1, 1, 1], \"SAME\") + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool_layer(in_tensors, sampling):\n",
    "    return tf.nn.max_pool(in_tensors, [1, sampling, sampling, 1], \n",
    "                          [1, sampling, sampling, 1], \"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(in_tensors, keep_proba, is_training):\n",
    "    return tf.cond(is_training, lambda:tf.nn.dropout(in_tensors, keep_proba),\n",
    "                  lambda:in_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Specification\n",
    "\n",
    "+ 2차원 convolution 5 * 5, 32 필터\n",
    "+ 2차원 convolution 5 * 5, 64 필터\n",
    "+ 평면화 계층(Flat Layer)\n",
    "+ Full Connected Layer, 1024개의 unit\n",
    "+ Dropout 40%\n",
    "+ Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(in_tensors, is_training):\n",
    "    # First Layer : 5*5 2d convolution layer, 32filters, 2x maxpool, 20% dropout\n",
    "    with tf.variable_scope(\"L1\"):\n",
    "        l1 = maxpool_layer(conv_layer(in_tensors, 5, 32), 2)\n",
    "        l1_out = dropout(l1, 0.8, is_training)\n",
    "    \n",
    "    # Second Layer : 5*5 2d conv layer, 64filters, 2x maxpool, 20% dropout\n",
    "    with tf.variable_scope(\"L2\"):\n",
    "        l2 = maxpool_layer(conv_layer(in_tensors, 5, 64), 2)\n",
    "        l2_out = dropout(l2, 0.8, is_training)\n",
    "        \n",
    "    # Flat Layer\n",
    "    with tf.variable_scope(\"flatten\"):\n",
    "        l2_out_flat = tf.layers.flatten(l2_out)\n",
    "        \n",
    "    # Fully Connected Layer, 1024 neurons, 40% dropout\n",
    "    with tf.variable_scope(\"L3\"):\n",
    "        l3 = fc_layer(l2_out_flat, 1024)\n",
    "        l3_out = dropout(l3, 0.6, is_training)\n",
    "        \n",
    "    # output\n",
    "    with tf.variable_scope(\"out\"):\n",
    "        out_tensors = fc_no_activation_layer(l3_out, N_CLASSES)\n",
    "    \n",
    "    return out_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, learning_rate, max_epochs, batch_size):\n",
    "    in_X_tensors_batch = tf.placeholder(tf.float32, shape=(None, \n",
    "                                                           RESIZED_IMAGE[0],\n",
    "                                                           RESIZED_IMAGE[1],1))\n",
    "    in_y_tensors_batch = tf.placeholder(tf.float32, shape=(None, N_CLASSES))\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    \n",
    "    logit = model(in_X_tensors_batch, is_training)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                labels=in_y_tensors_batch))\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            print(\"Epoch=\", epoch)\n",
    "            tf_score = []\n",
    "            \n",
    "            for mb in minibatcher(X_train, y_train, batch_size, shuffle=True):\n",
    "                _, c = sess.run([train, cost], \n",
    "                                feed_dict={in_X_tensors_batch:mb[0],\n",
    "                                                  in_y_tensors_batch:mb[1],\n",
    "                                                  is_training:True})\n",
    "                tf_score.append(c)\n",
    "                \n",
    "            print(\" train loss score=\", np.mean(tf_score))\n",
    "        \n",
    "        \n",
    "        # 훈련이 끝난 후 테스트\n",
    "        print(\"TEST SET PERFORMANCE\")\n",
    "            \n",
    "        out_y_pred = tf.nn.softmax(logit)\n",
    "        y_test_pred, test_cost = sess.run([out_y_pred, cost], \n",
    "                                          feed_dict={in_X_tensors_batch:X_test,\n",
    "                                                  in_y_tensors_batch:y_test,\n",
    "                                                  is_training:False})\n",
    "            \n",
    "        print(\" test_loss_score=\", test_cost)\n",
    "        y_test_pred_classified = np.argmax(y_test_pred, axis=1).astype(np.int32)\n",
    "        y_test_true_classified = np.argmax(y_test, axis=1).astype(np.int32)\n",
    "        print(classification_report(y_test_true_classified, y_test_pred_classified))\n",
    "    \n",
    "        cm = confusion_matrix(y_test_true_classified, y_test_pred_classified)\n",
    "    \n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.colorbar()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "        # And the log2 version, to enphasize the misclassifications\n",
    "        plt.imshow(np.log2(cm + 1), interpolation='nearest', cmap=plt.get_cmap(\"tab20\"))\n",
    "        plt.colorbar()\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-32-207eb419253a>:2: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-33-aa0ac3f1fe9a>:14: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "Epoch= 0\n",
      " train loss score= 14.751022\n",
      "Epoch= 1\n",
      " train loss score= 0.8720121\n",
      "Epoch= 2\n",
      " train loss score= 0.5362196\n",
      "Epoch= 3\n",
      " train loss score= 0.38509822\n",
      "Epoch= 4\n",
      " train loss score= 0.28633818\n",
      "Epoch= 5\n",
      " train loss score= 0.26213452\n",
      "Epoch= 6\n",
      " train loss score= 0.23379408\n",
      "Epoch= 7\n",
      " train loss score= 0.18945366\n",
      "Epoch= 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-331d485a3f76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-526bc4dbb6cc>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(X_train, y_train, learning_rate, max_epochs, batch_size)\u001b[0m\n\u001b[0;32m     23\u001b[0m                                 feed_dict={in_X_tensors_batch:mb[0],\n\u001b[0;32m     24\u001b[0m                                                   \u001b[0min_y_tensors_batch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                                                   is_training:True})\n\u001b[0m\u001b[0;32m     26\u001b[0m                 \u001b[0mtf_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "train_model(X_train, y_train, 0.001, 10, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. 일부 CNN계층과 FC계층을 추가를 통해서 성능이 어떻게 변하는지 확인\n",
    "2. dropout의 비율을 변경해보면서 결과가 과소적합 또는 과대적합되는지 확인\n",
    "3. 전체 epoch수와 batch size도 변경해서 결과 확인\n",
    "4. 실제 테스트 이미지를 통해 사용할 수 있는 프로그램 작성\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
